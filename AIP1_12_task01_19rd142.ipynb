{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIP1_12_task01_19rd142.ipynb ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loITRM43_-CQ"
      },
      "source": [
        "## 各種 API\n",
        "### numpy\n",
        "各種数値計算を高速で行う(中身は C++ライブラリらしい)\n",
        "公式：https://numpy.org/  \n",
        "ただし，日本語でもたくさん解説してくれているサイトがあるので，ググった方が早い場合もある\n",
        "\n",
        "今回のプログラムは class (オブジェクト指向)を使っているので注意．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qPZmH3KlzK-"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from copy import deepcopy as cp\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuO72YWSBaif"
      },
      "source": [
        "### バンディットマシーン本体のクラス\n",
        "バンディットマシーン≒スロットマシーン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6_pt6WeEHIg"
      },
      "source": [
        "r\"\"\"指定確率で1/0を返すバンディトマシーン提供モジュール\"\"\"\n",
        "\n",
        "class Bandit(object):\n",
        "    r\"\"\"指定確率で1/0を返すバンディットマシーン Class\n",
        "    \n",
        "    param\n",
        "    -----\n",
        "    prob(float): default:0.5\n",
        "        [0,1]の当たり確率指定値.\n",
        "\n",
        "    attr\n",
        "    ----\n",
        "    _prob(float):\n",
        "        あたり確率\n",
        "    _past(list of int):\n",
        "        報酬系列\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, prob=0.5):\n",
        "        if prob < 0 or prob > 1:\n",
        "            prob = random.random() \n",
        "        self._prob = prob # 当たり確率\n",
        "        self._past = [] # 過去の報酬系列\n",
        "\n",
        "    @property\n",
        "    def prob(self):\n",
        "        \"\"\"現在の設定確率を返す.\"\"\"\n",
        "        return self._prob\n",
        "        \n",
        "    def play(self):\n",
        "        r\"\"\"バンディットマシーンのプレイを行い、当たり/外れで1/0の報酬を返す.\"\"\"\n",
        "        if self._prob > random.random():\n",
        "            self._past.append(1)\n",
        "            return 1\n",
        "        else:\n",
        "            self._past.append(0)\n",
        "            return 0\n",
        "    \n",
        "    def print_average(self):\n",
        "        \"\"\"平均報酬、プレイ回数、真の確率を表示する.\"\"\"\n",
        "        mean = np.mean(self._past) if self._past else 0\n",
        "        num = len(self._past)\n",
        "#         print(f'ave:{mean}, n:{num}, tv:{self._prob}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1nNbXNlBlAT"
      },
      "source": [
        "### バンディットマシーンをプレイするエージェントのクラス\n",
        "探索手法(メタ方策)の関数もここが持っている．  \n",
        "課題では当該の関数を書き換えて方策を適切に実装する．  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYyemfOZEQwH"
      },
      "source": [
        "\"\"\"可能行為を受け取り、ポリシーに従いactionを実行するAgent提供モジュール\"\"\" \n",
        "\n",
        "class Agent(object):\n",
        "    \"\"\"add_actionで可能行為を受け取り、playで行為を選択・実行するAgent Class.\n",
        "    \n",
        "    attr\n",
        "    ----\n",
        "    _list_action(list of function):\n",
        "        可能行為のlist\n",
        "    _reward(list of int):\n",
        "        今迄得た報酬系列\n",
        "    _epsilon(float):\n",
        "        ランダム行動選択率\n",
        "    _Q(np.array(float)):\n",
        "        行動価値\n",
        "    _n(np.array(int)):\n",
        "        行動カウント\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, policy):\n",
        "        \"\"\"初期化処理\"\"\"\n",
        "        self._list_action = [] # action(スロットマシン)の登録\n",
        "        self._reward = []\n",
        "        self._epsilon = 0.0\n",
        "        self._Q = None\n",
        "        self._n = None\n",
        "\n",
        "# 課題ごとにここを変えて実行\n",
        "        if policy == 'e-greedy':\n",
        "            self.behavior = self._e_greedy\n",
        "        elif policy == 'softmax':\n",
        "            self.behavior = self._softmax   # 課題1    \n",
        "        elif policy == 'ucb1':\n",
        "            self.behavior = self._ucb1  # 課題2\n",
        "        else :\n",
        "            self.behavior = self._greedy\n",
        "\n",
        "\n",
        "    @property\n",
        "    def epsilon(self):\n",
        "        return self._epsilon\n",
        "    \n",
        "    @epsilon.setter\n",
        "    def epsilon(self, eps):\n",
        "        self._epsilon = eps\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"エージェントの初期化\"\"\"\n",
        "        # 各action(スロットマシン)の(その trial での agent の)主観的な価値\n",
        "        self._Q = np.zeros((len(self._list_action)))\n",
        "        # 各action(スロットマシン)の(その trial での agent の)試行回数\n",
        "        self._n = np.zeros((len(self._list_action)))\n",
        "      \n",
        "    def _update(self, act, rwd):\n",
        "        \"\"\"行動価値の更新()\"\"\"\n",
        "        self._n[act] += 1\n",
        "        self._Q[act] += (rwd - self._Q[act]) / self._n[act]\n",
        "        \n",
        "    def add_action(self, action):\n",
        "        \"\"\"可能行為を追加する.\"\"\"\n",
        "        self._list_action.append(action)\n",
        "        self._reward.append([])\n",
        "\n",
        "    def play(self, step):\n",
        "        \"\"\"ポリシーに従い、可能行為を選択・実行する\"\"\"\n",
        "        act = self.behavior(step)\n",
        "        rwd = self._list_action[act]()\n",
        "        self._reward[act].append(rwd)\n",
        "        self._update(act, rwd)\n",
        "        \n",
        "        return act, rwd\n",
        "\n",
        "    def _greedy(self, step):\n",
        "        \"\"\"平均報酬が最大である行為をグリーディに選択する.\"\"\"\n",
        "        # 平均報酬が最大である行為のインデックスをリスト\n",
        "        idx = np.where(self._Q == max(self._Q))[0]\n",
        "        #リストしたインデックスを返す,複数ある場合はランダム\n",
        "        select = random.choice(idx)\n",
        "\n",
        "        return select\n",
        "      \n",
        "    def _e_greedy(self, step):\n",
        "        epsilon = 0.1\n",
        "        if random.random() > epsilon:\n",
        "            select = self._greedy(step)\n",
        "        else:\n",
        "            select = random.choice(list(range(len(self._list_action))))\n",
        "\n",
        "        return select\n",
        "\n",
        "    def _softmax(self, step):\n",
        "        # 課題1 はここを正しい物に変える\n",
        "        tau = 0.1 # 温度パラメータ # ヒント\n",
        "        # \"ここに正しい確率を計算するコードを追加\" # ヒント\n",
        "        y = self / step\n",
        "        select = np.random.choice(list(range(len(self._list_action))), p = y)# ヒント\n",
        "        dummy = 0 # 常に 0 番目を引くダミー変数\n",
        "        select = dummy\n",
        "        return select\n",
        "\n",
        "\n",
        "    def _ucb1(self, step):\n",
        "        # 課題2 はここを正しい物に変える\n",
        "        c = 1.0\n",
        "        n_sum = np.sum(self._n)\n",
        "        # 全ての選択肢を一回は選択しなければならない\n",
        "        if n_sum < len(self._list_action): \n",
        "            return int(n_sum)\n",
        "        #u = #ヒント\n",
        "        idx = np.where(u == max(u))[0] # ヒント\n",
        "        select = random.choice(idx) # ヒント\n",
        "        dummy = 0 # 常に 0 番目を引くダミー変数\n",
        "        select = dummy\n",
        "        return select\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdbsmlAuB18T"
      },
      "source": [
        "### シミュレーション全体を管理するクラス\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOtFY1HPEUUc"
      },
      "source": [
        "\"\"\"n本腕バンディットシミュレーションのモジュール\"\"\"\n",
        "\n",
        "class BanditSimulator(object):\n",
        "    \"\"\"指定数でn本腕バンディットをシミュレートするClass.\n",
        "\n",
        "    param\n",
        "    -----\n",
        "    episode(int): default: 1000\n",
        "        実行するエピソード数\n",
        "\n",
        "    attr\n",
        "    ----\n",
        "    _num(int):\n",
        "        実行するエピソード数\n",
        "    _agent(Agent):\n",
        "        バンディットをプレイするエージェント\n",
        "    _bandit(list of Bandit):\n",
        "        バンディットマシーンのリスト\n",
        "    _correct(list of int):\n",
        "        n本腕の中で最も当たり確率が高い腕の選択系列\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, tr=100, n=10000, policy='greedy'):\n",
        "        self._trial = tr\n",
        "        self._num = n\n",
        "        self._agent = Agent(policy)\n",
        "        self._bandit = []\n",
        "        self._correct = np.zeros((tr, n))\n",
        "        self._correct_arm = None\n",
        "        self._select = np.zeros((tr, n))\n",
        "        self._regret = np.zeros((tr, n))\n",
        "    \n",
        "    def add_arm(self, prob=0.5):\n",
        "        \"\"\"指定確率のバンディットマシーンを追加する.\"\"\"\n",
        "        bd = Bandit(prob)\n",
        "        self._bandit.append(bd)\n",
        "        self._agent.add_action(bd.play)\n",
        "\n",
        "    def add_random_n_arm(self, n_arm):\n",
        "        \"\"\"n_arm 個のランダムな当たり確率バンディットマシーンを追加する\"\"\"\n",
        "        for _ in range(n_arm):\n",
        "            self.add_arm(random.random()/1.5)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"シミュレーションの実行.\"\"\"\n",
        "        arm_pb = [bd.prob for bd in self._bandit]\n",
        "        self._correct_arm = np.where(arm_pb == np.max(arm_pb))[0]        \n",
        "\n",
        "        time_start = time.time()\n",
        "        print(f\"trial: {self._trial}\", )\n",
        "        for i in range(self._trial):\n",
        "            if i %20 == 0:\n",
        "                print()\n",
        "                print(f\"t: \", end=\"\")\n",
        "            print(f\"{i}, \", end=\"\")\n",
        "            self._agent.reset()\n",
        "            for j in range(self._num):\n",
        "#                 print(f\"s: {j}\")\n",
        "                select, result = self._agent.play(j)\n",
        "                self._correct[i, j] = 1 if select in self._correct_arm else 0\n",
        "                self._select[i, j] = select\n",
        "                self._regret[i, j] = self._calc_regret(i, j)\n",
        "#                 print(f'select arm {select}, result {\"win\" if result == 1 else \"lose\"}')\n",
        "#             self.print_bandit_data()\n",
        "        time_end = time.time()\n",
        "        print()\n",
        "        print(f\"time: {time_end - time_start} (s)\", )\n",
        "\n",
        "        self.print_regret()\n",
        "\n",
        "    def print_bandit_data(self):\n",
        "        \"\"\"各バンディットマシーンのデータを表示する.\"\"\"\n",
        "        for bd in self._bandit:\n",
        "            bd.print_average()\n",
        "\n",
        "    def print_regret(self):\n",
        "        plt.plot(np.arange(self._num), np.mean(self._regret, axis=0))\n",
        "        plt.show()\n",
        "        print(\"final regret: {0:.5f}\".format(np.mean(self._regret, axis=0)[-1]), )\n",
        "        np.mean(self._regret, axis=0)\n",
        "    \n",
        "    def _calc_regret(self, tr, st):\n",
        "        \"\"\"regret の計算\"\"\"\n",
        "        diff = 0\n",
        "        if not int(self._correct[tr,st]):\n",
        "            diff = (self._bandit[self._correct_arm[0]].prob - self._bandit[int(self._select[tr, st])].prob)\n",
        "        pre = 0\n",
        "        if st != 0:\n",
        "            pre =  st - 1        \n",
        "        return self._regret[tr, pre] + diff\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYxrIsyB7_L"
      },
      "source": [
        "### バンディット問題シミュレーションを行うの関数\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alKWQgaLM1iI"
      },
      "source": [
        "def recreation_arm_bandit(tr=1, num=100, policy='greedy'):\n",
        "    sim = BanditSimulator(tr, num, policy)\n",
        "    p_true = [0.45, 0.5, 0.55, 0.6]\n",
        "    p_copy = cp(p_true)\n",
        "    for i in range(len(p_true)):\n",
        "      index = random.choice(list(range(len(p_copy))))\n",
        "      p_tmp = p_copy.pop(index)\n",
        "      print(f\"arm p: {p_tmp}\")\n",
        "      sim.add_arm(p_tmp)\n",
        "\n",
        "    sim.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxTacCFLYBci"
      },
      "source": [
        "## 実行\n",
        "※ 上記 Agent Class を書き換えて実行する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSTCKwzlw_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "5f54f5c6-e9b4-4d96-9a8c-e6e2e4c97bb5"
      },
      "source": [
        "tr = 200\n",
        "num = 5000\n",
        "recreation_arm_bandit(tr, num, 'e-greedy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arm p: 0.45\n",
            "arm p: 0.5\n",
            "arm p: 0.55\n",
            "arm p: 0.6\n",
            "trial: 200\n",
            "\n",
            "t: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, \n",
            "t: 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n",
            "t: 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, \n",
            "t: 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, \n",
            "t: 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, \n",
            "t: 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, \n",
            "t: 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, \n",
            "t: 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, \n",
            "t: 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, \n",
            "t: 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, \n",
            "time: 16.9299738407135 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "final regret: 95.62000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87JmusOoj8D1"
      },
      "source": [
        "## 課題1\n",
        "softmax 方策を実装する  \n",
        "※ 上記 Agent Class を書き換えてから実行する  \n",
        "※ τ=1 で良いがもっと後悔の度合いがよくなる数値があるならそれでも良い"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMeRdhxzkITW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "6c2d55c4-c4e6-4be7-8ef4-b640d5885ccd"
      },
      "source": [
        "tr = 200\n",
        "num = 5000\n",
        "recreation_arm_bandit(tr, num, 'softmax')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arm p: 0.55\n",
            "arm p: 0.45\n",
            "arm p: 0.5\n",
            "arm p: 0.6\n",
            "trial: 200\n",
            "\n",
            "t: 0, "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-f62de8a0266f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecreation_arm_bandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-162-1f5aa7e2497c>\u001b[0m in \u001b[0;36mrecreation_arm_bandit\u001b[0;34m(tr, num, policy)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_arm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-161-3af0b066173a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#                 print(f\"s: {j}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_correct_arm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-477b45a6a0ba>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"ポリシーに従い、可能行為を選択・実行する\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbehavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mrwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-477b45a6a0ba>\u001b[0m in \u001b[0;36m_softmax\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# \"ここに正しい確率を計算するコードを追加\" # ヒント\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# ヒント\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# 常に 0 番目を引くダミー変数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_PV4lYnj_jQ"
      },
      "source": [
        "## 課題2\n",
        "UCB1方策を実装する  \n",
        "※ 上記 Agent Class を書き換えてから実行する  \n",
        "※ c=2 で良いがもっと後悔の度合いがよくなる数値があるならそれでも良い"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hfzkfE9kJJp"
      },
      "source": [
        "tr = 200\n",
        "num = 5000\n",
        "recreation_arm_bandit(tr, num, 'ucb1')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}